#!/usr/bin/env python3
"""
MinuteMate Backend Service
Background service for meeting audio capture, transcription, and minutes generation
"""

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import tempfile
import json
from datetime import datetime
import whisper
import re
import threading
import time

app = Flask(__name__)
CORS(app)

# Global variables for background service
current_session = None
is_recording = False
audio_buffer = []
recording_start_time = None
silence_timer = None
SILENCE_THRESHOLD = 30  # 30 seconds of silence

# Initialize Whisper model (tiny for speed, offline)
try:
    print("Loading Whisper-tiny model...")
    model = whisper.load_model("tiny")
    print("Whisper-tiny model loaded successfully!")
except Exception as e:
    print(f"Error loading Whisper model: {e}")
    model = None

def silence_detection_timer():
    """Background thread to detect 30 seconds of silence"""
    global is_recording, current_session, silence_timer
    
    while is_recording:
        time.sleep(1)  # Check every second
        
        if not is_recording:
            break
            
        # Simulate silence detection (in real implementation, this would analyze audio levels)
        # For now, we'll use a simple timer that triggers after 30 seconds
        elapsed = time.time() - recording_start_time
        if elapsed >= SILENCE_THRESHOLD and is_recording:
            print(f"üîá Silence detected after {SILENCE_THRESHOLD} seconds - auto-stopping")
            is_recording = False
            break
    
    silence_timer = None

@app.route('/')
def index():
    """Serve the main HTML file"""
    return send_from_directory('static', 'index.html')

@app.route('/static/<path:filename>')
def static_files(filename):
    """Serve static files"""
    return send_from_directory('static', filename)

@app.route('/status')
def get_status():
    """GET /status returns 'recording' or 'idle'"""
    global is_recording, current_session
    
    if is_recording and current_session:
        return jsonify({
            'status': 'recording',
            'session_id': current_session['id'],
            'duration': time.time() - recording_start_time if recording_start_time else 0
        })
    
    return jsonify({'status': 'idle'})

@app.route('/start', methods=['POST'])
def start_recording():
    """Start background recording service"""
    global current_session, is_recording, audio_buffer, recording_start_time, silence_timer
    
    if is_recording:
        return jsonify({'error': 'Already recording'}), 400
    
    # Initialize new session
    current_session = {
        'id': datetime.now().strftime('%Y%m%d_%H%M%S'),
        'start_time': datetime.now().isoformat(),
        'audio_chunks': []
    }
    
    is_recording = True
    audio_buffer = []
    recording_start_time = time.time()
    
    # Start silence detection timer
    silence_timer = threading.Thread(target=silence_detection_timer, daemon=True)
    silence_timer.start()
    
    print(f"üéôÔ∏è Recording session started: {current_session['id']}")
    print(f"üîá Silence detection enabled (auto-stop after {SILENCE_THRESHOLD}s)")
    
    return jsonify({
        'message': 'Recording started',
        'session_id': current_session['id']
    })

@app.route('/stop', methods=['POST'])
def stop_recording():
    """Stop recording and process audio"""
    global is_recording, current_session, audio_buffer, silence_timer
    
    if not is_recording:
        return jsonify({'error': 'Not recording'}), 400
    
    is_recording = False
    session_id = current_session['id'] if current_session else None
    
    # Stop silence detection timer
    if silence_timer and silence_timer.is_alive():
        silence_timer.join(timeout=1)
    
    print(f"‚èπÔ∏è Recording stopped for session: {session_id}")
    
    return jsonify({
        'message': 'Recording stopped',
        'session_id': session_id
    })

@app.route('/transcribe', methods=['POST'])
def transcribe_audio():
    """Process uploaded audio and generate transcript"""
    global current_session
    
    if 'audio' not in request.files:
        return jsonify({'error': 'No audio file provided'}), 400
    
    audio_file = request.files['audio']
    
    try:
        # Save audio to temporary WAV file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            audio_file.save(temp_file.name)
            temp_path = temp_file.name
        
        print(f"üéµ Processing audio file: {temp_path}")
        
        # Transcribe using Whisper-tiny
        if model is None:
            return jsonify({'error': 'Whisper model not loaded'}), 500
        
        result = model.transcribe(temp_path)
        transcript = result['text'].strip()
        
        print(f"‚úÖ Transcription completed: {len(transcript)} characters")
        
        # Clean up temp file
        os.unlink(temp_path)
        
        # Update session
        if current_session:
            current_session['transcript'] = transcript
            current_session['transcription_time'] = datetime.now().isoformat()
        
        return jsonify({
            'transcript': transcript,
            'language': result.get('language', 'en')
        })
        
    except Exception as e:
        print(f"‚ùå Transcription error: {e}")
        return jsonify({'error': f'Transcription failed: {str(e)}'}), 500

@app.route('/generate-minutes', methods=['POST'])
def generate_minutes():
    """Generate meeting minutes from transcript"""
    global current_session
    
    data = request.get_json()
    transcript = data.get('transcript', '')
    
    if not transcript:
        return jsonify({'error': 'No transcript provided'}), 400
    
    try:
        # Simple NLP processing as specified
        minutes = generate_minutes_from_transcript(transcript)
        
        # Update session
        if current_session:
            current_session['minutes'] = minutes
            current_session['completion_time'] = datetime.now().isoformat()
        
        return jsonify({'minutes': minutes})
        
    except Exception as e:
        print(f"‚ùå Minutes generation error: {e}")
        return jsonify({'error': f'Minutes generation failed: {str(e)}'}), 500

@app.route('/minutes/<session_id>')
def get_minutes(session_id):
    """GET /minutes/{id} returns JSON with summary, actions, reminders"""
    # For now, return current session minutes
    # In production, you'd load from database/file
    global current_session
    
    if not current_session or current_session['id'] != session_id:
        return jsonify({'error': 'Session not found'}), 404
    
    return jsonify({
        'session_id': session_id,
        'transcript': current_session.get('transcript', ''),
        'minutes': current_session.get('minutes', ''),
        'start_time': current_session.get('start_time', ''),
        'completion_time': current_session.get('completion_time', '')
    })

def generate_minutes_from_transcript(transcript):
    """Simple NLP processing: split into chunks, generate summary, extract actions"""
    
    # Split transcript into sentences
    sentences = [s.strip() for s in re.split(r'[.!?]+', transcript) if s.strip()]
    
    # Split into ‚â§1000-token chunks (approximate: 1 token ‚âà 4 characters)
    MAX_CHARS_PER_CHUNK = 4000  # 1000 tokens * 4 characters per token
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) > MAX_CHARS_PER_CHUNK:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence
        else:
            current_chunk += " " + sentence if current_chunk else sentence
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    print(f"üìù Split transcript into {len(chunks)} chunks (max {MAX_CHARS_PER_CHUNK} chars each)")
    
    # Process each chunk for action items and dates
    all_action_items = []
    all_dates = []
    
    for i, chunk in enumerate(chunks):
        print(f"üîç Processing chunk {i+1}/{len(chunks)}: {len(chunk)} characters")
        
        # Extract action items from this chunk
        action_words = ['will', 'need to', 'should', 'must', 'going to', 'plan to']
        chunk_sentences = [s.strip() for s in re.split(r'[.!?]+', chunk) if s.strip()]
        
        for sentence in chunk_sentences:
            if any(word in sentence.lower() for word in action_words):
                all_action_items.append(sentence)
        
        # Extract dates from this chunk
        date_pattern = r'\b\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\b|\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \d{1,2},? \d{4}\b'
        chunk_dates = re.findall(date_pattern, chunk)
        all_dates.extend(chunk_dates)
    
    # Generate 200-word summary
    if len(transcript) > 200:
        summary = transcript[:200] + "..."
    else:
        summary = transcript
    
    # Format minutes as specified
    minutes = f"""Meeting Minutes - {datetime.now().strftime('%B %d, %Y')}

üìã Summary ({len(summary)} words):
{summary}

‚úÖ Action Items ({len(all_action_items)} found):
"""
    
    for i, action in enumerate(all_action_items[:5], 1):  # Limit to 5 actions
        minutes += f"{i}. {action}\n"
    
    if not all_action_items:
        minutes += "‚Ä¢ No specific action items identified\n"
    
    minutes += f"""

üìÖ Dates Mentioned ({len(all_dates)} found):
"""
    
    for i, date in enumerate(all_dates[:3], 1):  # Limit to 3 dates
        minutes += f"{i}. {date}\n"
    
    if not all_dates:
        minutes += "‚Ä¢ No specific dates mentioned\n"
    
    minutes += f"""

üîç Key Topics:
‚Ä¢ Meeting duration: {len(sentences)} main discussion points
‚Ä¢ Transcript chunks: {len(chunks)} segments processed
‚Ä¢ Focus areas: {', '.join(sentences[:3])}
‚Ä¢ Next steps: Review action items and set deadlines
"""
    
    return minutes

if __name__ == '__main__':
    print("üéôÔ∏è MinuteMate Background Service Starting...")
    print("=" * 50)
    print("Project Requirements:")
    print("‚Ä¢ Background service for live meeting audio")
    print("‚Ä¢ Offline Whisper-tiny transcription")
    print("‚Ä¢ Simple NLP processing (regex-based)")
    print("‚Ä¢ REST API: /status, /minutes/{id}")
    print("‚Ä¢ Web UI with live status polling")
    print("=" * 50)
    
    if model is None:
        print("‚ö†Ô∏è  Warning: Whisper model not loaded")
    
    app.run(host='0.0.0.0', port=5000, debug=True) 